# module_4 Проект 4. Компьютер говорит «Нет»

В этом модуле нас ждёт путь от стажёра отдела аналитики регионального банка до… Будем считать, что почти до начальника отдела! 

Что мы успеете сделать по дороге?

Напишем скоринговую модель предсказания дефолта клиентов банка.
Поучаствуем в командном хакатоне (на этот раз приготовлен неожиданный формат).
По доброй традиции обогатим своё портфолио.

Итак, по легенде, спустя несколько часов составления SQL-запросов мы наконец собрали датасет. 
Посмотрим на данные:
* client_id	- идентификатор клиента
* education	- уровень образования
* sex	- пол заёмщика
* age	- возраст заёмщика
* car	- флаг наличия автомобиля
* car_type	- флаг автомобиля-иномарки
* decline_app_cnt	- количество отказанных прошлых заявок
* good_work	- флаг наличия «хорошей» работы
* bki_request_cnt	- количество запросов в БКИ
* home_address	- категоризатор домашнего адреса
* work_address	- категоризатор рабочего адреса
* income	- доход заёмщика
* foreign_passport	- наличие загранпаспорта
* default	- наличие дефолта

Идем по плану,
1. Читаем данные
  В датасете test нет признака "default". Мы должны предсказать значение указанного признака, предварительно заполним его нулями. 
2. Предварительный анализ данных
  Пропуски только в поле 'education', поработаем с ним - заполняем пропущенные значения наиболее часто встречающимся "SCH" (окончил школу)
3. Анализ и преобразование данных
  добавим в датасет кол-во заявок, поданных в каждую дату по данным датасета train
  добавим в датасет кол-во дефолтов, на каждую дату поданной заявки по данным датасета train
  на основе добавленных признаков создадим новый - доля дефолтов от кол-ва поданных заявок
  для признаков "age", "bki_request_cnt", "income" распределение логарифов более нормальное. Поэтому заменим значения этих признаков в датасете на логарифмы. 
4. Оценка значимости признаков
  преобразуем бинарные даные с помощью метода fit класса LabelEncoder
  преобразуем категориальный признак "education"
  Оценим корреляции - Признаки слабо коррелированы между собой, все признаки будем использовать в модели
5. Строим модель
  преобразуем категориальные признаки методом One-Hot Encoding
  стандартизируем числовые признаки методом StandardScaler
  строим модель методом LogisticRegression
6. Оценка качества модели
  Визуализация confusion matrix:
    Полученная модель плохо предсказывает заемщиков, которые в будущем могут не выплачить кредиты.
  ROC-анализ
    Значения различаются не сильно, переобучения нет. Посмотрим, можно ли найти более оптимальные параметры для модели.
7. Поиск оптимальных значений гиперпараметров
  ищем оптимальные значения гиперпараметров с помощью GridSearchCV
  Строим модель с подобранными гиперпарметрами
  Визуализация confusion matrix:
    Эта модель лучше предсказывает неблагонадежных клиентов.
  ROC-анализ
    Расхождение метрики ROC AUC для обучающей и тестовоый выборок не изменилось. Будем использовать модель с подобранными гиперпараметрами.
8. Определяем значение дефолта клиентов
9. Вывод
  Метрики улучшаются на сотые доли. После обработки датасета и добавления новых признаков была сгенерирована базовая модель логистической регрессии, которая показала ROC AUC >     0.74. Модель была донастроена с подбором параметров через GridSearchCV. Для дальнейшего усовершенствования модели может быть необходимо создать новые признаки или придумать     какие-либо решения со значениями, которые вызывают сомнение в рамках IQR.
